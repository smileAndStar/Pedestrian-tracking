#All global paths and program configuration

#dataset specific parameters
datasetDir = /absolute/path/to/your/dataset/directory/
backgroundImg = /absolute/path/to/the/background/image/bg.jpg

# width & height are needed for saving the output video, if they are wrong the video won't open
frameWidth = 640
frameHeight = 480


#general parameters
exportAsVideo = true                        # if set to false the result will be exported to images
trackingExportDir = /absolute/path/to/your/desired/output/directory
detectionsCoordsImportDir = /for/example/your/full/path/to/PedestrianTracking/data/detections/ktp/yolo


#Detection module parameters
DetectionMethod = Yolo                      # possible values: {Yolo, BSI}.
                                            # Yolo: detection with yolo neural network,
                                            # BSI: Background Subtraction with Inception network
importDetectionsFromFiles = true
exportDetectionsOnly = false                # only used for experimentations (set it to false for real application)

#Yolo parameters
yoloThreshold = 0.50                        # dont accept detections with confidence lower than this threshold
hierThreshold = 0.5

#Background subtraction parameters
useClassifier = true                        # the inception classifier is used in combination with bkgd subtraction to eliminate false positives
exportBinaryImgs = false
doBkgdSubtractionPostProcessing = true      # only used for experimentations (set it to true for real application)
neglegibleDistance = 40     #(in pixels)    # used to connect separaeted body parts from background subtraction
neglegibleRectArea = 300    #(in pixels)    # used by background subtraction module to ignore small changes that cannot represent humans,
                                            # use small value when camera is far from the people, and larger value otherwise.
#Parameters for the retrained inception model
inceptionClassifierPath = /your/path/to/tensorflow/bazel-bin/tensorflow/examples/image_retraining/label_image
inceptionModelPath = /your/path/to/PedestrianTracking/data/inception/model/output_graph.pb
inceptionLabelsPath = /your/path/to/PedestrianTracking/data/inception/model/output_labels.txt
tmpImgPath = /tmp/imgToClassify.jpg         # for saving the detected ROI to be classified
minimumAcceptedConfidence = 0.90            # minimum confidence level from the classifier to accept its classification as human


#Tracking module parameters
fps=30
accelNoiseMag = 0.7                         # Acceleration noise magnitude for Kalman filter
distanceThreshold=1.2                       # to filter out wrong assignments of far objects
maxSkippedFrames = 1    #(in seconeds)      #maximum allowed skipped frames when object disappear
